{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DnLV1HUefFtW"
   },
   "source": [
    "# Text Features and Embeddings In CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0UAHpnD8fFtZ"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/catboost/tutorials/blob/master/events/2020_11_18_catboost_tutorial/text_embedding_features.ipynb)\n",
    "\n",
    "\n",
    "**Set GPU as hardware accelerator**\n",
    "\n",
    "First of all, you need to select GPU as hardware accelerator. There are two simple steps to do so:\n",
    "Step 1. Navigate to **Runtime** menu and select **Change runtime type**\n",
    "Step 2. Choose **GPU** as hardware accelerator.\n",
    "That's all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9FM0IRyi8NOw"
   },
   "source": [
    "Let's install CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "MNC1tP0UfFtd",
    "outputId": "2c0abe55-df9c-4a0f-daa4-dc8c8d858f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=4)\n",
    "\n",
    "import catboost\n",
    "print(catboost.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Youtube [tutorial](https://youtu.be/lB0WYoz5nU4?t=2029)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkexL1k7fFti"
   },
   "source": [
    "# Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "viF18QJqfFtd"
   },
   "source": [
    "In this tutorial we will use dataset **IMDB** from [Kaggle](https://www.kaggle.com) competition for our experiments. Data can be downloaded [here](https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('imdb.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  One of the other reviewers has mentioned that ...      1\n",
       "1  A wonderful little production. <br /><br />The...      1\n",
       "2  I thought this was a wonderful way to spend ti...      1\n",
       "3  Basically there's a family where a little boy ...      0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = (df['sentiment'] == 'positive').astype(int)\n",
    "df.drop(['sentiment'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.label.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train test split\n",
    "train_df, test_df = train_test_split(df, train_size=0.8, random_state=0)\n",
    "\n",
    "# split targets and text\n",
    "y_train, X_train = train_df['label'], train_df.drop(['label'], axis=1)\n",
    "y_test, X_test = test_df['label'], test_df.drop(['label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAD4CAYAAADGmmByAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYr0lEQVR4nO3da7BlZX3n8e8vtBJMRBFap9NNp1HbC1Da2i1DxZhSSYaWmQjMYNJMShiHSSvBKa3kheCkojVTXSUzo2SYjBgUissoFwWF1EgmqBmZVLh4MITmIvEgKMfugvZSQrxgGv/zYj8nszm9z+ndvc7e221/P1Wrztr/tZ69n6e66/zOs9baa6WqkCRpf/3cpDsgSZpuBokkqRODRJLUiUEiSerEIJEkdbJi0h0YtyOOOKLWrVs36W5I0lS58847v1VVKwdtO+CCZN26dczMzEy6G5I0VZJ8fbFtHtqSJHVikEiSOjFIJEmdGCSSpE4MEklSJwaJJKmTkQVJkiOT/GWS+5Pcm+Rdrf68JDcn+Wr7eVhfm/OSzCZ5IMmJffWNSba3bRcmSasfnOSaVr89ybpRjUeSNNgoZyS7gT+oqpcDxwPnJDkaOBf4fFWtBz7fXtO2bQGOATYDH05yUHuvi4CtwPq2bG71s4DvVtWLgQuA80c4HknSACMLkqraWVVfbutPAPcDq4GTgcvbbpcDp7T1k4Grq+rJqnoImAWOS7IKOLSqbq3ew1OuWNBm/r0+BZwwP1uRJI3HWL7Z3g45vQq4HXhBVe2EXtgkeX7bbTVwW1+zuVb7h7a+sD7f5pH2XruTfA84HPjWgs/fSm9Gw9q1a/d7HOvO/V/73barhz/wzyf22ZKWz8/i75GRn2xP8ovAdcC7q+rxpXYdUKsl6ku1eXqh6uKq2lRVm1auHHirGEnSfhppkCR5Br0Q+XhVXd/Kj7bDVbSfj7X6HHBkX/M1wI5WXzOg/rQ2SVYAzwG+s/wjkSQtZpRXbQW4BLi/qj7Ut+lG4My2fiZwQ199S7sS6yh6J9XvaIfBnkhyfHvPMxa0mX+v04AvlA+hl6SxGuU5ktcCbwW2J7mr1d4LfAC4NslZwDeAtwBU1b1JrgXuo3fF1zlV9VRrdzZwGXAIcFNboBdUVyaZpTcT2TLC8UiSBhhZkFTVXzH4HAbACYu02QZsG1CfAY4dUP8RLYgkSZPhN9slSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ2M8pntlyZ5LMk9fbVrktzVlofnH8GbZF2SH/Zt+0hfm41JtieZTXJhe2477dnu17T67UnWjWoskqTFjXJGchmwub9QVb9dVRuqagNwHXB93+YH57dV1Tv66hcBW4H1bZl/z7OA71bVi4ELgPNHMgpJ0pJGFiRVdQvwnUHb2qzit4CrlnqPJKuAQ6vq1qoq4ArglLb5ZODytv4p4IT52YokaXwmdY7kdcCjVfXVvtpRSf4myReTvK7VVgNzffvMtdr8tkcAqmo38D3g8EEflmRrkpkkM7t27VrOcUjSAW9SQXI6T5+N7ATWVtWrgN8HPpHkUGDQDKPaz6W2Pb1YdXFVbaqqTStXruzQbUnSQivG/YFJVgD/Etg4X6uqJ4En2/qdSR4EXkJvBrKmr/kaYEdbnwOOBObaez6HRQ6lSZJGZxIzkl8HvlJV/3jIKsnKJAe19RfSO6n+taraCTyR5Ph2/uMM4IbW7EbgzLZ+GvCFdh5FkjRGo7z89yrgVuClSeaSnNU2bWHPk+y/Btyd5G/pnTh/R1XNzy7OBj4GzAIPAje1+iXA4Ulm6R0OO3dUY5EkLW5kh7aq6vRF6v9mQO06epcDD9p/Bjh2QP1HwFu69VKS1JXfbJckdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdTLKR+1emuSxJPf01d6f5JtJ7mrLSX3bzksym+SBJCf21Tcm2d62Xdie3U6Sg5Nc0+q3J1k3qrFIkhY3yhnJZcDmAfULqmpDWz4LkORoes9yP6a1+XCSg9r+FwFbgfVtmX/Ps4DvVtWLgQuA80c1EEnS4kYWJFV1C/CdIXc/Gbi6qp6sqoeAWeC4JKuAQ6vq1qoq4ArglL42l7f1TwEnzM9WJEnjM4lzJO9Mcnc79HVYq60GHunbZ67VVrf1hfWntamq3cD3gMMHfWCSrUlmkszs2rVr+UYiSRp7kFwEvAjYAOwEPtjqg2YStUR9qTZ7FqsurqpNVbVp5cqV+9RhSdLSxhokVfVoVT1VVT8BPgoc1zbNAUf27boG2NHqawbUn9YmyQrgOQx/KE2StEzGGiTtnMe8U4H5K7puBLa0K7GOondS/Y6q2gk8keT4dv7jDOCGvjZntvXTgC+08yiSpDFaMao3TnIV8HrgiCRzwPuA1yfZQO8Q1MPA2wGq6t4k1wL3AbuBc6rqqfZWZ9O7AuwQ4Ka2AFwCXJlklt5MZMuoxiJJWtzIgqSqTh9QvmSJ/bcB2wbUZ4BjB9R/BLylSx8lSd35zXZJUicGiSSpE4NEktSJQSJJ6sQgkSR1YpBIkjoxSCRJnRgkkqRODBJJUicGiSSpE4NEktSJQSJJ6sQgkSR1YpBIkjoxSCRJnRgkkqRORhYkSS5N8liSe/pq/yXJV5LcneTTSZ7b6uuS/DDJXW35SF+bjUm2J5lNcmF75C7tsbzXtPrtSdaNaiySpMUNFSRJ9nhC4RAuAzYvqN0MHFtVrwD+Djivb9uDVbWhLe/oq18EbKX3HPf1fe95FvDdqnoxcAFw/n70UZLU0bAzko8kuSPJ783PIvamqm6h9yz1/tpfVNXu9vI2YM1S75FkFXBoVd1aVQVcAZzSNp8MXN7WPwWcMD9bkSSNz1BBUlW/CvwOcCQwk+QTSX6j42f/W+CmvtdHJfmbJF9M8rpWWw3M9e0z12rz2x5p/dsNfA84vGOfJEn7aMWwO1bVV5P8ITADXAi8qs0A3ltV1+/Lhyb5D8Bu4OOttBNYW1XfTrIR+EySY4BBM4yaf5slti38vK30Do+xdu3afemqJGkvhj1H8ookFwD3A28EfrOqXt7WL9iXD0xyJvAvgN9ph6uoqier6ttt/U7gQeAl9GYg/Ye/1gA72vocvRkSSVYAz2HBobR5VXVxVW2qqk0rV67cl+5KkvZi2HMkfwJ8GXhlVZ1TVV8GqKodwB8O+2FJNgPvAd5cVT/oq69MclBbfyG9k+pfq6qdwBNJjm+znzOAG1qzG4Ez2/ppwBfmg0mSND7DHto6CfhhVT0FkOTngJ+vqh9U1ZWDGiS5Cng9cESSOeB99K7SOhi4uZ0Xv61dofVrwH9Msht4CnhHVc3PLs6mdwXYIfTOqcyfV7kEuDLJLL2ZyJZhBy1JWj7DBsnngF8H/r69fhbwF8CvLNagqk4fUL5kkX2vA65bZNsMsMflx1X1I+AtS/ZakjRywx7a+vmqmg8R2vqzRtMlSdI0GTZIvp/k1fMv2pVVPxxNlyRJ02TYQ1vvBj6ZZP6KqVXAb4+kR5KkqTJUkFTVl5K8DHgpve9vfKWq/mGkPZMkTYWhv5AIvAZY19q8KglVdcVIeiVJmhpDBUmSK4EXAXfRuzwXet8iN0gk6QA37IxkE3C0X/iTJC007FVb9wD/ZJQdkSRNp2FnJEcA9yW5A3hyvlhVbx5JryRJU2PYIHn/KDshSZpew17++8Ukvwysr6rPJXkWcNBouyZJmgbD3kb+d+k9hfBPW2k18JkR9UmSNEWGPdl+DvBa4HHoPeQKeP6oOiVJmh7DBsmTVfXj+RftQVJeCixJGjpIvpjkvcAh7VntnwT+bHTdkiRNi2GD5FxgF7AdeDvwWfbhyYiSpJ9dw1619RPgo22RJOkfDXvV1kNJvrZw2UubS5M8luSevtrzktyc5Kvt52F9285LMpvkgSQn9tU3Jtnetl3Ynt1OkoOTXNPqtydZt8+jlyR1NuyhrU307v77GuB1wIXA/9xLm8uAzQtq5wKfr6r1wOfba5IcTe+Z68e0Nh9OMv89lYuArcD6tsy/51nAd6vqxcAFwPlDjkWStIyGCpKq+nbf8s2q+mPgjXtpcwvwnQXlk4HL2/rlwCl99aur6smqegiYBY5Lsgo4tKpubTeMvGJBm/n3+hRwwvxsRZI0PsPeRv7VfS9/jt4M5dn78XkvqKqdAFW1M8n8d1FWA7f17TfXav/Q1hfW59s80t5rd5LvAYcD3xrQ/630ZjWsXbt2P7otSVrMsPfa+mDf+m7gYeC3lrEfg2YStUR9qTZ7FqsuBi4G2LRpk99/kaRlNOxVW29Yps97NMmqNhtZBTzW6nPAkX37rQF2tPqaAfX+NnPtC5LPYc9DaZKkERv20NbvL7W9qj405OfdCJwJfKD9vKGv/okkHwJ+id5J9Tuq6qkkTyQ5HrgdOAP47wve61bgNOALPnhLksZvX56Q+Bp6v7wBfhO4hXaOYpAkVwGvB45IMge8j16AXJvkLOAbwFsAqureJNcC99E7dHZOVc0/0vdseleAHQLc1BaAS4Ark8zSm4lsGXIskqRltC8Ptnp1VT0BkOT9wCer6t8t1qCqTl9k0wmL7L8N2DagPgMcO6D+I1oQSZImZ9jvkawFftz3+sfAumXvjSRp6gw7I7kSuCPJp+ldGXUqve90SJIOcMNetbUtyU30vtUO8Laq+pvRdUuSNC2GPbQF8Czg8ar6b/QuuT1qRH2SJE2RYW/a+D7gPcB5rfQM9n6vLUnSAWDYGcmpwJuB7wNU1Q727xYpkqSfMcMGyY/bl/0KIMkvjK5LkqRpMmyQXJvkT4HnJvld4HP4kCtJEkNctdVuzX4N8DLgceClwB9V1c0j7pskaQrsNUiqqpJ8pqo2AoaHJOlphj20dVuS14y0J5KkqTTsN9vfALwjycP0rtwKvcnKK0bVMUnSdFgySJKsrapvAG8aU38kSVNmbzOSz9C76+/Xk1xXVf9qDH2SJE2RvZ0j6X+c7QtH2RFJ0nTaW5DUIuuSJAF7P7T1yiSP05uZHNLW4f+fbD90pL2TJP3UW3JGUlUHVdWhVfXsqlrR1udf71eIJHlpkrv6lseTvDvJ+5N8s69+Ul+b85LMJnkgyYl99Y1JtrdtF7YvT0qSxmhfbiO/LKrqgaraUFUbgI3AD4BPt80XzG+rqs8CJDma3vPYjwE2Ax9OclDb/yJgK7C+LZvHNxJJEkwgSBY4AXiwqr6+xD4nA1dX1ZNV9RAwCxyXZBVwaFXd2m4oeQVwysh7LEl6mkkHyRbgqr7X70xyd5JLkxzWaquBR/r2mWu11W19YX0PSbYmmUkys2vXruXrvSRpckGS5Jn0nnHyyVa6CHgRsAHYCXxwftcBzWuJ+p7FqouralNVbVq5cmWXbkuSFpjkjORNwJer6lGAqnq0qp6qqp/Qu0X9cW2/OeDIvnZrgB2tvmZAXZI0RpMMktPpO6zVznnMOxW4p63fCGxJcnB7Tvx64I6q2gk8keT4drXWGcAN4+m6JGnesDdtXFZJngX8BvD2vvJ/TrKB3uGph+e3VdW9Sa4F7gN2A+dU1VOtzdnAZcAhwE1tkSSN0USCpKp+ABy+oPbWJfbfBmwbUJ8Bjl32DkqShjbpq7YkSVPOIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSepkIkGS5OEk25PclWSm1Z6X5OYkX20/D+vb/7wks0keSHJiX31je5/ZJBe2Z7dLksZokjOSN1TVhqra1F6fC3y+qtYDn2+vSXI0sAU4BtgMfDjJQa3NRcBWYH1bNo+x/5IkfroObZ0MXN7WLwdO6atfXVVPVtVDwCxwXJJVwKFVdWtVFXBFXxtJ0phMKkgK+IskdybZ2movqKqdAO3n81t9NfBIX9u5Vlvd1hfW95Bka5KZJDO7du1axmFIklZM6HNfW1U7kjwfuDnJV5bYd9B5j1qivmex6mLgYoBNmzYN3EeStH8mMiOpqh3t52PAp4HjgEfb4Sraz8fa7nPAkX3N1wA7Wn3NgLokaYzGHiRJfiHJs+fXgX8G3APcCJzZdjsTuKGt3whsSXJwkqPonVS/ox3+eiLJ8e1qrTP62kiSxmQSh7ZeAHy6Xam7AvhEVf15ki8B1yY5C/gG8BaAqro3ybXAfcBu4Jyqeqq919nAZcAhwE1tkSSN0diDpKq+BrxyQP3bwAmLtNkGbBtQnwGOXe4+SpKG99N0+a8kaQoZJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ1M4pntRyb5yyT3J7k3ybta/f1Jvpnkrrac1NfmvCSzSR5IcmJffWOS7W3bhe3Z7ZKkMZrEM9t3A39QVV9O8mzgziQ3t20XVNV/7d85ydHAFuAY4JeAzyV5SXtu+0XAVuA24LPAZnxuuySN1dhnJFW1s6q+3NafAO4HVi/R5GTg6qp6sqoeAmaB45KsAg6tqlurqoArgFNG23tJ0kITPUeSZB3wKuD2VnpnkruTXJrksFZbDTzS12yu1Va39YX1QZ+zNclMkpldu3Yt5xAk6YA3sSBJ8ovAdcC7q+pxeoepXgRsAHYCH5zfdUDzWqK+Z7Hq4qraVFWbVq5c2bXrkqQ+EwmSJM+gFyIfr6rrAarq0ap6qqp+AnwUOK7tPgcc2dd8DbCj1dcMqEuSxmgSV20FuAS4v6o+1Fdf1bfbqcA9bf1GYEuSg5McBawH7qiqncATSY5v73kGcMNYBiFJ+keTuGrrtcBbge1J7mq19wKnJ9lA7/DUw8DbAarq3iTXAvfRu+LrnHbFFsDZwGXAIfSu1vKKLUkas7EHSVX9FYPPb3x2iTbbgG0D6jPAscvXO0nSvvKb7ZKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTgwSSVInBokkqRODRJLUiUEiSerEIJEkdWKQSJI6MUgkSZ0YJJKkTqY+SJJsTvJAktkk5066P5J0oJnqIElyEPA/gDcBR9N77vvRk+2VJB1YpjpIgOOA2ar6WlX9GLgaOHnCfZKkA8qKSXego9XAI32v54B/unCnJFuBre3l3yd5YD8/7wjgW/vZtpOcP4lPBSY45glyzAeGA27MOb/TmH95sQ3THiQZUKs9ClUXAxd3/rBkpqo2dX2faeKYDwyO+cAwqjFP+6GtOeDIvtdrgB0T6oskHZCmPUi+BKxPclSSZwJbgBsn3CdJOqBM9aGtqtqd5J3A/wYOAi6tqntH+JGdD49NIcd8YHDMB4aRjDlVe5xSkCRpaNN+aEuSNGEGiSSpE4NkgL3ddiU9F7btdyd59ST6uZyGGPPvtLHeneSvk7xyEv1cTsPeXifJa5I8leS0cfZvFIYZc5LXJ7kryb1JvjjuPi6nIf5fPyfJnyX52zbet02in8spyaVJHktyzyLbl//3V1W59C30Tto/CLwQeCbwt8DRC/Y5CbiJ3vdYjgdun3S/xzDmXwEOa+tvOhDG3LffF4DPAqdNut9j+Hd+LnAfsLa9fv6k+z3i8b4XOL+trwS+Azxz0n3vOO5fA14N3LPI9mX//eWMZE/D3HblZOCK6rkNeG6SVePu6DLa65ir6q+r6rvt5W30vrMzzYa9vc6/B64DHhtn50ZkmDH/a+D6qvoGQFVN87iHGW8Bz04S4BfpBcnu8XZzeVXVLfTGsZhl//1lkOxp0G1XVu/HPtNkX8dzFr2/aKbZXsecZDVwKvCRMfZrlIb5d34JcFiS/5PkziRnjK13y2+Y8f4J8HJ6X2TeDryrqn4ynu5NzLL//prq75GMyDC3XRnq1ixTZOjxJHkDvSD51ZH2aPSGGfMfA++pqqd6f7BOvWHGvALYCJwAHALcmuS2qvq7UXduBIYZ74nAXcAbgRcBNyf5v1X1+Ij7NknL/vvLINnTMLdd+Vm7NctQ40nyCuBjwJuq6ttj6tuoDDPmTcDVLUSOAE5KsruqPjOWHi6/Yf9vf6uqvg98P8ktwCuBaQySYcb7NuAD1Tt5MJvkIeBlwB3j6eJELPvvLw9t7WmY267cCJzRrn44HvheVe0cd0eX0V7HnGQtcD3w1in963ShvY65qo6qqnVVtQ74FPB7UxwiMNz/7RuA1yVZkeRZ9O6mff+Y+7lchhnvN+jNvkjyAuClwNfG2svxW/bfX85IFqhFbruS5B1t+0foXcFzEjAL/IDeXzVTa8gx/xFwOPDh9hf67priO6cOOeafKcOMuaruT/LnwN3AT4CPVdXAy0h/2g35b/yfgMuSbKd3yOc9VTXVt5ZPchXweuCIJHPA+4BnwOh+f3mLFElSJx7akiR1YpBIkjoxSCRJnRgkkqRODBJJUicGiSSpE4NEktTJ/wM9SxSYMXvotAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_test.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset shape: (40000, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for simplicity create pools instead of every time passing X,y\n",
    "train_pool = Pool(data=X_train, label=y_train, text_features=['review'])\n",
    "test_pool = Pool(data=X_test, label=y_test, text_features=['review'])\n",
    "\n",
    "print('Train dataset shape: {}\\n'.format(train_pool.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline**, without preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "VTi3eN58fFt6",
    "outputId": "e694fed2-1341-45a3-c799-334b32fbc01e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "526bf6f8313f43a19aca3fc620990205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "def fit_model(train_pool, test_pool, **kwargs):\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=1200,\n",
    "        learning_rate=0.1,\n",
    "        eval_metric='AUC',\n",
    "        custom_loss=['AUC', 'Accuracy'],\n",
    "        leaf_estimation_method='Newton',\n",
    "        l2_leaf_reg=5,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    return model.fit(\n",
    "        train_pool,\n",
    "        eval_set=test_pool,\n",
    "        verbose=False,\n",
    "        plot=True,\n",
    "    )\n",
    "\n",
    "# can specify task_type='GPU'\n",
    "# in Colab task_type='GPU' will not work with plotting\n",
    "model = fit_model(train_pool, test_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for the record:\n",
    "* AUC = 0.9559\n",
    "* Accuracy = 0.8961"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IiHpTGfbfFuV"
   },
   "source": [
    "**How it works?**\n",
    "There are three main steps when dealing with text features.\n",
    "\n",
    "1. **Text Tokenization**\n",
    "2. **Dictionary Creation**\n",
    "3. **Feature Calculation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MszSnbqH8NR3"
   },
   "source": [
    "## Text Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mOBGuexjb8tr"
   },
   "source": [
    "Usually we get our text as a sequence of Unicode symbols. So, if the task isn't a DNA classification we don't need such granularity, moreover, we need to extract more complicated entities, e.g. words. The process of extraction tokens -- words, numbers, punctuation symbols or special symbols which defines emoji from a sequence is called **tokenization**.<br>\n",
    "\n",
    "Tokenization is the first part of text preprocessing in CatBoost and performed as a simple splitting a sequence on a string pattern (e.g. space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NAeELULufFuV"
   },
   "outputs": [],
   "source": [
    "text_small = [\n",
    "    \"Cats are so cute :)\",\n",
    "    \"Mouse scare...\",\n",
    "    \"The cat defeated the mouse\",\n",
    "    \"Cute: Mice gather an army!\",\n",
    "    \"Army of mice defeated the cat :(\",\n",
    "    \"Cat offers peace\",\n",
    "    \"Cat is scared :(\",\n",
    "    \"Cat and mouse live in peace :)\"\n",
    "]\n",
    "\n",
    "target_small = [1, 0, 1, 1, 0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with simple tokenizer with default parameters, they are passed explicetely. Some interesting parameters are\n",
    "* `number_process_policy` - The strategy to process numeric tokens. Possible values:\n",
    "    * Skip — Skip all numeric tokens.\n",
    "    * LeaveAsIs — Leave all numeric tokens as is.\n",
    "    * Replace — Replace all numeric tokens with a single special token. This token in specified in the number_token parameter.\n",
    "\n",
    "* `number_token` - The special token that is used to replace all numeric tokens with. This option can be used if the selected numeric tokens processing strategy is Replace.\n",
    "\n",
    "* `separator_type` - The tokenization method. Possible values:\n",
    "    * ByDelimiter — Split by delimiter (default).\n",
    "    * BySense — Try to split the string by sense.\n",
    "* `split_by_set` - Use each single character in the `delimiter` option as an individual delimiter\n",
    "* `token_types` - The types of tokens that should be kept after the tokenization. Should be used if the separator_type parameter is set to BySense. Possible values (by default all supported types of tokens are kept):\n",
    "    * Word\n",
    "    * Number\n",
    "    * Punctuation\n",
    "    * SentenceBreak\n",
    "    * ParagraphBreak\n",
    "    * Unknown\n",
    "* `sub_tokens_policy` - The subtokens processing policy. Should be used if the separator_type parameter is set to BySense. Possible values:\n",
    "    * SingleToken — All subtokens are interpreted as a single token (default).\n",
    "    * SeveralTokens — All subtokens are interpreted as several tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "E21CQ8ocfFuX",
    "outputId": "f78b995b-29fc-41c9-b28c-b3adee167ba7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Cats', 'are', 'so', 'cute', ':)'],\n",
       " ['Mouse', 'scare...'],\n",
       " ['The', 'cat', 'defeated', 'the', 'mouse'],\n",
       " ['Cute:', 'Mice', 'gather', 'an', 'army!'],\n",
       " ['Army', 'of', 'mice', 'defeated', 'the', 'cat', ':('],\n",
       " ['Cat', 'offers', 'peace'],\n",
       " ['Cat', 'is', 'scared', ':('],\n",
       " ['Cat', 'and', 'mouse', 'live', 'in', 'peace', ':)']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost.text_processing import Tokenizer\n",
    "\n",
    "simple_tokenizer = Tokenizer(\n",
    "    lowercasing=False,\n",
    "    lemmatizing=False,\n",
    "    number_process_policy='LeaveAsIs',\n",
    "    number_token=None,  # Numeric tokens are left as is\n",
    "    separator_type='ByDelimiter',\n",
    "    delimiter=' ',\n",
    "    split_by_set=False,\n",
    "    skip_empty=True,\n",
    "    token_types=None,\n",
    "    sub_tokens_policy=None,\n",
    "    languages=None\n",
    ")\n",
    "    \n",
    "def tokenize_texts(texts):\n",
    "    return [simple_tokenizer.tokenize(text) for text in texts]\n",
    "\n",
    "simple_tokenized_text = tokenize_texts(text_small)\n",
    "simple_tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ChZQ5cpJfFuZ"
   },
   "source": [
    "Lets take a closer look on the tokenization result of small text example -- the tokens contains a lot of mistakes:\n",
    "\n",
    "1. They are glued with punctuation 'Cute:', 'army!', 'skare...'.\n",
    "2. The words 'Cat' and 'cat', 'Mice' and 'mice' seems to have same meaning, perhaps they should be the same tokens.\n",
    "3. The same problem with tokens 'are'/'is' -- they are inflected forms of same token 'be'.\n",
    "\n",
    "**Punctuation handling**, **lowercasing**, and **lemmatization** processes help to overcome these problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qaoTjEmR8NSM"
   },
   "source": [
    "### Punctuation handling and lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "6cPpYpmtfFuZ",
    "outputId": "2bc7abef-5828-43af-d588-48edb490eed9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cats', 'are', 'so', 'cute'],\n",
       " ['mouse', 'scare'],\n",
       " ['the', 'cat', 'defeated', 'the', 'mouse'],\n",
       " ['cute', 'mice', 'gather', 'an', 'army'],\n",
       " ['army', 'of', 'mice', 'defeated', 'the', 'cat'],\n",
       " ['cat', 'offers', 'peace'],\n",
       " ['cat', 'is', 'scared'],\n",
       " ['cat', 'and', 'mouse', 'live', 'in', 'peace']]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(\n",
    "    lowercasing=True,\n",
    "    separator_type='BySense',\n",
    "    token_types=['Word', 'Number']\n",
    ")\n",
    "\n",
    "tokenized_text = [tokenizer.tokenize(text) for text in text_small]\n",
    "tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JDhBkZzJfFua"
   },
   "source": [
    "### Removing stop words\n",
    "\n",
    "**Stop words** - the words that are considered to be uninformative in this task, e.g. function words such as *the, is, at, which, on*.\n",
    "Usually stop words are removed during text preprocessing to reduce the amount of information that is considered for further algorithms.\n",
    "Stop words are collected manually (in dictionary form) or automatically, for example taking the most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "d1MYzKgTfFub",
    "outputId": "865f655e-0cb9-4626-9d40-e459b9487b0f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cats', 'so', 'cute'],\n",
       " ['mouse', 'scare'],\n",
       " ['cat', 'defeated', 'mouse'],\n",
       " ['cute', 'mice', 'gather', 'army'],\n",
       " ['army', 'mice', 'defeated', 'cat'],\n",
       " ['cat', 'offers', 'peace'],\n",
       " ['cat', 'scared'],\n",
       " ['cat', 'mouse', 'live', 'peace']]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(('be', 'is', 'are', 'the', 'an', 'of', 'and', 'in'))\n",
    "\n",
    "def filter_stop_words(tokens):\n",
    "    return list(filter(lambda x: x not in stop_words, tokens))\n",
    "    \n",
    "tokenized_text_no_stop = [filter_stop_words(tokens) for tokens in tokenized_text]\n",
    "tokenized_text_no_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vxofPVc1fFuc"
   },
   "source": [
    "### Lemmatization\n",
    "\n",
    "Lemma (Wikipedia) -- is the canonical form, dictionary form, or citation form of a set of words.<br>\n",
    "For example, the lemma \"go\" represents the inflected forms \"go\", \"goes\", \"going\", \"went\", and \"gone\".<br>\n",
    "The process of convertation word to its lemma called **lemmatization**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "HWrijpMGfFud",
    "outputId": "1b6b8015-8cf9-47c5-89cf-5d5fc8b5f794"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /opt/anaconda3/envs/catboost/lib/python3.9/site-\n",
      "[nltk_data]     packages/nltk/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk_data_path = os.path.join(os.path.dirname(nltk.__file__), 'nltk_data')\n",
    "nltk.data.path.append(nltk_data_path)\n",
    "nltk.download('wordnet', nltk_data_path)\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens_nltk(tokens):\n",
    "    return list(map(lambda t: lemmatizer.lemmatize(t), tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "XfyhV9ONfFuf",
    "outputId": "4b0568c9-3bb8-483a-8f86-dd358c6fd2c5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to /home/stankvla/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['cat', 'so', 'cute'],\n",
       " ['mouse', 'scare'],\n",
       " ['cat', 'defeated', 'mouse'],\n",
       " ['cute', 'mouse', 'gather', 'army'],\n",
       " ['army', 'mouse', 'defeated', 'cat'],\n",
       " ['cat', 'offer', 'peace'],\n",
       " ['cat', 'scared'],\n",
       " ['cat', 'mouse', 'live', 'peace']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')\n",
    "text_small_lemmatized_nltk = [lemmatize_tokens_nltk(tokens) for tokens in tokenized_text_no_stop]\n",
    "text_small_lemmatized_nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y63KVna4fFui"
   },
   "source": [
    "Now words with same meaning represented by the same token, tokens are not glued with punctuation.\n",
    "\n",
    "<span style=\"color:red\">Be carefull.</span> You should verify for your own task:<br>\n",
    "Is it realy necessary to remove punctuation, lowercasing sentences or performing a lemmatization and/or by word tokenization?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qFWoSX-kfFui"
   },
   "source": [
    "### Let's check up accuracy with new text preprocessing\n",
    "\n",
    "Since CatBoost doesn't perform spacing punctuation, lowercasing letters and lemmatization, we need to preprocess text manually and then pass it to learning algorithm.\n",
    "\n",
    "Since the natural text features is only synopsis and review, we will preprocess only them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "ZHL3x7NwfFuj",
    "outputId": "85135452-02ea-4644-882d-726fcc568605"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.4 s, sys: 51.4 ms, total: 29.5 s\n",
      "Wall time: 29.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = Tokenizer(\n",
    "    lowercasing=True,\n",
    "    separator_type='BySense',\n",
    "    token_types=['Word', 'Number']\n",
    ")\n",
    "\n",
    "def preprocess_data(X):\n",
    "    X_preprocessed = X.copy()\n",
    "    X_preprocessed['review'] = X['review'].apply(lambda x: ' '.join(lemmatize_tokens_nltk(tokenizer.tokenize(x))))\n",
    "    return X_preprocessed\n",
    "\n",
    "X_preprocessed_train = preprocess_data(X_train)\n",
    "X_preprocessed_test = preprocess_data(X_test)\n",
    "\n",
    "train_processed_pool = Pool(\n",
    "    X_preprocessed_train, y_train, \n",
    "    text_features=['review'],\n",
    ")\n",
    "\n",
    "test_processed_pool = Pool(\n",
    "    X_preprocessed_test, y_test, \n",
    "    text_features=['review'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "id": "0jJJSrFJfFuk",
    "outputId": "6baeef42-d430-4793-fc33-556095416a9b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31428079d76f457b91d83af0ce4e6973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_on_processed_data = fit_model(train_processed_pool, test_processed_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we obtained the following results:\n",
    "* AUC = 0.9669\n",
    "* Accuracy = 0.9049"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "AXDdPAgyfFum",
    "outputId": "61e26e81-b858-4675-ab58-aaf3384428ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC      :: 0.9594 vs 0.9670 (+0.79%)\n",
      "Accuracy :: 0.8961 vs 0.9049 (+0.98%)\n"
     ]
    }
   ],
   "source": [
    "def print_score_diff(first_model, second_model, metric_name):\n",
    "    first_accuracy = first_model.best_score_['validation'][metric_name]\n",
    "    second_accuracy = second_model.best_score_['validation'][metric_name]\n",
    "\n",
    "    gap = (second_accuracy - first_accuracy) / first_accuracy * 100\n",
    "\n",
    "    print('{:8} :: {:.4f} vs {:.4f} ({:+.2f}%)'.format(metric_name, first_accuracy, second_accuracy, gap))\n",
    "    \n",
    "print_score_diff(model, model_on_processed_data, 'AUC')\n",
    "print_score_diff(model, model_on_processed_data, 'Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CJr7fXN7fFun"
   },
   "source": [
    "## Dictionary Creation\n",
    "\n",
    "The second stage uses the prepared text to select a set of units, which will be used for building new numerical features.\n",
    "\n",
    "A set of selected units is called dictionary. It might contain words, word bigramms, or character n-gramms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D6H1MXf9fFuo"
   },
   "outputs": [],
   "source": [
    "from catboost.text_processing import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['cat', 'so', 'cute'],\n",
       " ['mouse', 'scare'],\n",
       " ['cat', 'defeated', 'mouse'],\n",
       " ['cute', 'mouse', 'gather', 'army'],\n",
       " ['army', 'mouse', 'defeated', 'cat'],\n",
       " ['cat', 'offer', 'peace'],\n",
       " ['cat', 'scared'],\n",
       " ['cat', 'mouse', 'live', 'peace']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_small_lemmatized_nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating **Dictionary**, [docs](https://catboost.ai/en/docs/concepts/python-reference_dictionary), interesting parameters are the following:\n",
    "* `token_level_type`: Word(default) or Letter\n",
    "* `gram_order`: int, (1 is default), can be used for words and letters\n",
    "* `skip_step`: nt, (0 is default), gram_order should be > 1, \n",
    "    * if `skip_step=1, gram_order=2` than in sequence w1 w2 w3 w4 we would generate the following bigrams\n",
    "    * `[w1, w3]` and `[w2, w4]`, hence skipping one word in the bigram\n",
    "* `occurence_lower_bound`: The lower limit of token occurrences in the text to include it in the dictionary. Default is 50.\n",
    "* `max_dictionary_size`: The maximum number of tokens in the dictionary. Default is -1 (unlimited).\n",
    "* `dictionary_type`: Possible values:\n",
    "    * FrequencyBased (default). Takes into account only the most frequent tokens. The size of the dictionary and the lower limit of token occurrences in the text to include it in the dictionary are set in `occurence_lower_bound` and `max_dictionary_size` parameters respectively.\n",
    "    * Bpe. Takes into account the most frequent tokens and then makes new tokens from combinations of the most frequent token pairs. If selected, both the Frequency Based and Bpe dictionaries are created.\n",
    "* `num_bpe_units`: The number of token pairs that should be combined to a single token. The most popular tokens are combined into one and added to the dictionary as a new token (if `dictionary_type='Bpe'`). Default is 0.\n",
    "* `skip_unknown`: Skip unknown tokens when building the dictionary (if `dictionary_type='Bpe'`). Default is False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rn402k78fFuq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_catboost.Dictionary at 0x7fa8e189d270>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = Dictionary(\n",
    "    token_level_type='Word',\n",
    "    gram_order=1,\n",
    "    skip_step=0,\n",
    "    occurence_lower_bound=2\n",
    ")\n",
    "\n",
    "dictionary.fit(text_small_lemmatized_nltk)\n",
    "#dictionary.fit(text_small, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "colab_type": "code",
    "id": "KJr0UBzOfFur",
    "outputId": "4ab23b42-0fb7-4ac4-c878-63da839c8635"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"end_of_word_token_policy\":\"Insert\",\"skip_step\":\"0\",\"start_token_id\":\"0\",\"token_level_type\":\"Word\",\"dictionary_format\":\"id_count_token\",\"end_of_sentence_token_policy\":\"Skip\",\"gram_order\":\"1\"}\r\n",
      "6\r\n",
      "0\t6\tcat\r\n",
      "1\t5\tmouse\r\n",
      "2\t2\tarmy\r\n",
      "3\t2\tcute\r\n",
      "4\t2\tdefeated\r\n",
      "5\t2\tpeace\r\n"
     ]
    }
   ],
   "source": [
    "dictionary.save('dictionary.tsv')\n",
    "!cat dictionary.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 3]]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply dictionary on the first sentence\n",
    "dictionary.apply([text_small_lemmatized_nltk[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U1wLb5MX8NTY"
   },
   "source": [
    "## Feature Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KYzNqXgcfFut"
   },
   "source": [
    "### Convertation into fixed size vectors\n",
    "\n",
    "The majority of classic ML algorithms are computing and performing predictions on a fixed number of features $N$.<br>\n",
    "That means that learning set $X = \\{x_i\\}$ contains vectors $x_i = (a_0, a_1, ..., a_N)$ where $N$ is constant.\n",
    "\n",
    "Since text object $x$ is not a fixed length vector, we need to perform preprocessing of the origin set $D$.<br>\n",
    "One of the simplest text to vector encoding technique is **Bag of words (BoW)**.\n",
    "\n",
    "### Bag of words algorithm\n",
    "\n",
    "The algorithm takes in a dictionary and a text.<br>\n",
    "During the algorithm text $x = (a_0, a_1, ..., a_k)$ converted into vector $\\tilde x = (b_0, b_1, ..., b_F)$,<br> where $b_i$ is 0/1 (depending on whether there is a word with id=$i$ from dictionary into text $x$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tokenizer = Tokenizer(\n",
    "    lowercasing=False,\n",
    "    lemmatizing=False,\n",
    "    number_process_policy='LeaveAsIs',\n",
    "    number_token=None,  # Numeric tokens are left as is\n",
    "    separator_type='ByDelimiter',\n",
    "    delimiter=' ',\n",
    "    split_by_set=False,\n",
    "    skip_empty=True,\n",
    "    token_types=None,\n",
    "    sub_tokens_policy=None,\n",
    "    languages=None\n",
    ")\n",
    "N = 1000\n",
    "\n",
    "# create small training set\n",
    "X_proc_train_small, y_train_small = X_preprocessed_train[:N]['review'].to_list(), y_train[:N]\n",
    "# tokenize using simple tokenizer\n",
    "X_proc_train_small = list(map(simple_tokenizer.tokenize, X_proc_train_small))\n",
    "\n",
    "# create small validation set\n",
    "X_proc_test_small, y_test_small = X_preprocessed_test[:N]['review'].to_list(), y_test[:N]\n",
    "# tokenize using simple tokenizer\n",
    "X_proc_test_small = list(map(simple_tokenizer.tokenize, X_proc_test_small))\n",
    "\n",
    "dictionary = Dictionary(max_dictionary_size=100)\n",
    "dictionary.fit(X_proc_train_small);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_proc_train_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "ga0AfpT8fFuv",
    "outputId": "6b6e9abb-3e2a-4a8e-eac9-dacbac3c33fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create bag of words features\n",
    "def bag_of_words(tokenized_text, dictionary):\n",
    "    features = np.zeros((len(tokenized_text), dictionary.size))\n",
    "    for i, tokenized_sentence in enumerate(tokenized_text):\n",
    "        # here we take 0th object since dictionary returns list of lists\n",
    "        # in our case it is a list of one element (encoded sentence)\n",
    "        indices = np.array(dictionary.apply([tokenized_sentence])[0])\n",
    "        if len(indices) > 0:\n",
    "            # for every index set 1\n",
    "            features[i, indices] = 1\n",
    "    return features\n",
    "\n",
    "X_bow_train_small = bag_of_words(X_proc_train_small, dictionary)\n",
    "X_bow_test_small = bag_of_words(X_proc_test_small, dictionary)\n",
    "X_bow_train_small.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will see how dictionary size can effect model performance. We will use simple logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhr-EyPyfFuy"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def fit_linear_model(X, y):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_model_auc(model, X, y):\n",
    "    y_pred = model.predict_proba(X)[:,1]\n",
    "    metric = roc_auc_score(y, y_pred)\n",
    "    print('AUC: ' + str(metric))\n",
    "\n",
    "    \n",
    "def evaluate_linear_models(X_train, y_train, X_test, y_test):\n",
    "    linear_model = fit_linear_model(X_train, y_train)\n",
    "        \n",
    "    print('Linear model')\n",
    "    evaluate_model_auc(linear_model, X_test, y_test)\n",
    "    print('Comparing to constant prediction')\n",
    "    auc_constant_prediction = roc_auc_score(y_test, np.ones(shape=(len(y_test), 1)) * 0.5)\n",
    "    print('AUC: ' + str(auc_constant_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our baseline is model that used dictionary size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "GekNCx5ofFuz",
    "outputId": "5b218b73-c7fd-4628-f218-29d0d30686eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model\n",
      "AUC: 0.7158704813129555\n",
      "Comparing to constant prediction\n",
      "AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "evaluate_linear_models(X_bow_train_small, y_train_small, X_bow_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we increase dictionary size to 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "uFsAWNE9fFu2",
    "outputId": "7197acdf-71ac-4c81-b507-4f06cafdbea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1000)\n",
      "Linear model\n",
      "AUC: 0.8715258184961521\n",
      "Comparing to constant prediction\n",
      "AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "unigram_dictionary = Dictionary(occurence_lower_bound=0, max_dictionary_size=1000)\n",
    "unigram_dictionary.fit(X_proc_train_small)\n",
    "\n",
    "X_bow_train_small = bag_of_words(X_proc_train_small, unigram_dictionary)\n",
    "X_bow_test_small = bag_of_words(X_proc_test_small, unigram_dictionary)\n",
    "print(X_bow_train_small.shape)\n",
    "\n",
    "evaluate_linear_models(X_bow_train_small, y_train_small, X_bow_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously larger dictionary preserves more information and this results in better quality of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yvjUACB_fFu6"
   },
   "source": [
    "### Looking at sequences of letters / words\n",
    "\n",
    "Let's look at the example: \n",
    "* The cat defeated the mouse \n",
    "* Army of mice defeated the cat :(\n",
    "\n",
    "Simplifying it we have three tokens in each sentence 'cat defeat mouse' and 'mouse defeat cat'.<br>\n",
    "After applying BoW we get two equal vectors with the opposite meaning:\n",
    "\n",
    "| cat | mouse | defeat |\n",
    "|-----|-------|--------|\n",
    "| 1   | 1     | 1      |\n",
    "| 1   | 1     | 1      |\n",
    "\n",
    "How to distinguish them?\n",
    "Lets add sequences of words as a single tokens into our dictionary:\n",
    "\n",
    "| cat | mouse | defeat | cat_defeat | mouse_defeat | defeat_cat | defeat_mouse |\n",
    "|-----|-------|--------|------------|--------------|------------|--------------|\n",
    "| 1   | 1     | 1      | 1          | 0            | 0          | 1            |\n",
    "| 1   | 1     | 1      | 0          | 1            | 1          | 0            |\n",
    "\n",
    "**N-gram** is a sequence of $n$ items from a given sample of text or speech (Wikipedia).<br>\n",
    "In example above Bi-gram (Bigram) = 2-gram of words.\n",
    "\n",
    "Ngrams help to add into vectors more information about text structure, moreover there are n-grams has no meanings in separation, for example, 'Mickey Mouse company'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets tokenize our small text using bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 379
    },
    "colab_type": "code",
    "id": "WU6iWFPZClrf",
    "outputId": "b666b9a2-0782-472a-a729-0fa1b15bd9f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"end_of_word_token_policy\":\"Insert\",\"skip_step\":\"0\",\"start_token_id\":\"0\",\"token_level_type\":\"Word\",\"dictionary_format\":\"id_count_token\",\"end_of_sentence_token_policy\":\"Skip\",\"gram_order\":\"2\"}\r\n",
      "17\r\n",
      "0\t1\tarmy mouse\r\n",
      "1\t1\tcat defeated\r\n",
      "2\t1\tcat mouse\r\n",
      "3\t1\tcat offer\r\n",
      "4\t1\tcat scared\r\n",
      "5\t1\tcat so\r\n",
      "6\t1\tcute mouse\r\n",
      "7\t1\tdefeated cat\r\n",
      "8\t1\tdefeated mouse\r\n",
      "9\t1\tgather army\r\n",
      "10\t1\tlive peace\r\n",
      "11\t1\tmouse defeated\r\n",
      "12\t1\tmouse gather\r\n",
      "13\t1\tmouse live\r\n",
      "14\t1\tmouse scare\r\n",
      "15\t1\toffer peace\r\n",
      "16\t1\tso cute\r\n"
     ]
    }
   ],
   "source": [
    "dictionary = Dictionary(occurence_lower_bound=0, gram_order=2)\n",
    "dictionary.fit(text_small_lemmatized_nltk)\n",
    "\n",
    "dictionary.save('dictionary.tsv')\n",
    "!cat dictionary.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see all bigrams appeared only once in this small example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see if using bigrams will improve quality of our simple logistic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "ypPTi_XXfFu7",
    "outputId": "59136696-c457-4f99-b884-cf1e2e68fb80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 5000)\n",
      "Linear model\n",
      "AUC: 0.8281568279047059\n",
      "Comparing to constant prediction\n",
      "AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "bigram_dictionary = Dictionary(occurence_lower_bound=0, max_dictionary_size=5000, gram_order=2)\n",
    "bigram_dictionary.fit(X_proc_train_small)\n",
    "\n",
    "X_bow_train_small = bag_of_words(X_proc_train_small, bigram_dictionary)\n",
    "X_bow_test_small = bag_of_words(X_proc_test_small, bigram_dictionary)\n",
    "print(X_bow_train_small.shape)\n",
    "\n",
    "evaluate_linear_models(X_bow_train_small, y_train_small, X_bow_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see the quality is worse than in unigram model. It possibly means that for our task unigrams carry more information than bigrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1uLlIfJHodEL"
   },
   "source": [
    "### Unigram + Bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we have both unigram and bigram features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 125
    },
    "colab_type": "code",
    "id": "XaRC74kNfFu8",
    "outputId": "f67a5ea4-0795-4b16-db80-2bff733109e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 6000)\n",
      "Linear model\n",
      "AUC: 0.8916235457961653\n",
      "Comparing to constant prediction\n",
      "AUC: 0.5\n"
     ]
    }
   ],
   "source": [
    "# concatenate two matrices\n",
    "X_bow_train_small = np.concatenate((\n",
    "    bag_of_words(X_proc_train_small, unigram_dictionary),\n",
    "    bag_of_words(X_proc_train_small, bigram_dictionary)\n",
    "), axis=1)\n",
    "\n",
    "X_bow_test_small = np.concatenate((\n",
    "    bag_of_words(X_proc_test_small, unigram_dictionary),\n",
    "    bag_of_words(X_proc_test_small, bigram_dictionary)\n",
    "), axis=1)\n",
    "\n",
    "print(X_bow_train_small.shape)\n",
    "\n",
    "evaluate_linear_models(X_bow_train_small, y_train_small, X_bow_test_small, y_test_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that bigrams add additional information, that unigrams can not capture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oFR_rMfH8NT_"
   },
   "source": [
    "## CatBoost Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, how to use all these tricks in catboost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xoFAOiz8NT_"
   },
   "source": [
    "Parameter names:\n",
    "\n",
    "1. **Text Tokenization** - `tokenizers`\n",
    "2. **Dictionary Creation** - `dictionaries`\n",
    "3. **Feature Calculation** - `feature_calcers`\n",
    "\n",
    "\\* More complex configuration with `text_processing` parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wntt3XrYgkhf"
   },
   "source": [
    "### `tokenizers`\n",
    "\n",
    "Tokenizers used to preprocess Text type feature columns before creating the dictionary. Tokenizer will be a list of dicts, each dict represent one tokenizer. It is important to set `tokenizerId=\"MyTokenizerName\"` to some unique name, other params are passed to the tokenizer constructor.\n",
    "\n",
    "[Documentation](https://catboost.ai/docs/references/tokenizer_options.html).\n",
    "\n",
    "```\n",
    "tokenizers = [{\n",
    "        'tokenizerId': 'Space',\n",
    "        'delimiter': ' ',\n",
    "        'separator_type': 'ByDelimiter',\n",
    "    },{\n",
    "        'tokenizerId': 'Sense',\n",
    "        'separator_type': 'BySense',\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aKqHyav7fFu-"
   },
   "source": [
    "### `dictionaries`\n",
    "\n",
    "Dictionaries used to preprocess Text type feature columns. Dictionaries are created the same way, we need specify `dictionaryId` and parameters of the dictionary.\n",
    "\n",
    "[Documentation](https://catboost.ai/docs/references/dictionaries_options.html).\n",
    "\n",
    "```\n",
    "dictionaries = [{\n",
    "        'dictionaryId': 'Unigram',\n",
    "        'max_dictionary_size': '50000',\n",
    "        'gram_count': '1',\n",
    "    },{\n",
    "        'dictionaryId': 'Bigram',\n",
    "        'max_dictionary_size': '50000',\n",
    "        'gram_count': '2',\n",
    "    },{\n",
    "        'dictionaryId': 'Trigram',\n",
    "        'token_level_type': 'Letter',\n",
    "        'max_dictionary_size': '50000',\n",
    "        'gram_count': '3',\n",
    "    }\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JT6I_LN98NUC"
   },
   "source": [
    "### `feature_calcers`\n",
    "\n",
    "Feature calcers used to calculate new features based on preprocessed Text type feature columns.\n",
    "\n",
    "1. **`BoW`**<br>\n",
    "Bag of words: 0/1 features (text sample has or not token_id).<br>\n",
    "Number of produced numeric features = dictionary size.<br>\n",
    "Parameters: `top_tokens_count` - maximum number of tokens that will be used for vectorization in bag of words, the most frequent $n$ tokens are taken (**highly affect both on CPU ang GPU RAM usage**).\n",
    "\n",
    "2. **`NaiveBayes`**<br>\n",
    "NaiveBayes: [Multinomial naive bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier#Multinomial_naive_Bayes) model. As many new features as classes are added. This feature is calculated by analogy with counters in CatBoost by permutation ([estimation of CTRs](https://catboost.ai/docs/concepts/algorithm-main-stages_cat-to-numberic.html)). In other words, a random permutation is made and then we go from top to bottom on the dataset and calculate the probability of its belonging to this class for each object.\n",
    "\n",
    "3. **`BM25`**<br>\n",
    "[BM25](https://en.wikipedia.org/wiki/Okapi_BM25). As many new features as classes are added. The idea is the same as in Naive Bayes, but for each class we calculate not the conditional probability, but a certain relevance, which is similar to tf-idf, where the tokens instead of the words and the classes instead of the documents (or rather, the unification of all texts of this class). Only the tf multiplier in BM25 is replaced with another multiplier, which gives an advantage to classes that contain rare tokens.\n",
    "\n",
    "```\n",
    "feature_calcers = [\n",
    "\t'BoW:top_tokens_count=1000',\n",
    "\t'NaiveBayes',\n",
    "\t'BM25',\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note**\n",
    "\n",
    "If we use\n",
    "```\n",
    "text_processing=dict(\n",
    "    tokenizers=tokenizers, \n",
    "    dictionaries=dictionaries, \n",
    "    feature_calcers=feature_calcers\n",
    ")\n",
    "``` \n",
    "(using dictionaries defined above) catboost will create a cartesian product of all available preprocessings (18 feature sets):\n",
    "* Space Unigram BoW\n",
    "* Space Unigram NaiveBayes\n",
    "* Space Unigram BM25\n",
    "* Space Bigram Bow\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02lH5f1PgpYM"
   },
   "source": [
    "### `text_processing`\n",
    "\n",
    "```\n",
    "text_processing_not_cartesian = {\n",
    "    \"tokenizers\" : [{\n",
    "        \"tokenizer_id\" : \"Space\",\n",
    "        \"separator_type\" : \"ByDelimiter\",\n",
    "        \"delimiter\" : \" \"\n",
    "    }],\n",
    "\n",
    "    \"dictionaries\" : [{\n",
    "        \"dictionary_id\" : \"BiGram\",\n",
    "        \"max_dictionary_size\" : \"50000\",\n",
    "        \"occurrence_lower_bound\" : \"3\",\n",
    "        \"gram_order\" : \"2\"\n",
    "    }, {\n",
    "        \"dictionary_id\" : \"Word\",\n",
    "        \"max_dictionary_size\" : \"50000\",\n",
    "        \"occurrence_lower_bound\" : \"3\",\n",
    "        \"gram_order\" : \"1\"\n",
    "    }],\n",
    "\n",
    "    \"feature_processing\" : {\n",
    "        \"default\" : [{\n",
    "            \"dictionaries_names\" : [\"BiGram\", \"Word\"],\n",
    "            \"feature_calcers\" : [\"BoW\"],\n",
    "            \"tokenizers_names\" : [\"Space\"]\n",
    "        }, {\n",
    "            \"dictionaries_names\" : [\"Word\"],\n",
    "            \"feature_calcers\" : [\"NaiveBayes\"],\n",
    "            \"tokenizers_names\" : [\"Space\"]\n",
    "        }],\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important note**\n",
    "\n",
    "If we use `text_processing_not_cartesian` we will create only 2 set of features. `default` in `feature_processing` means that we use this preprocessing for all text features, we can specify feature name to use different preprocessing for different features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xlo77dzufFvE"
   },
   "source": [
    "## Summary: Text features in CatBoost\n",
    "\n",
    "### The algorithm:\n",
    "1. Input text is loaded as a usual column. ``text_column: [string]``.\n",
    "2. Each text sample is tokenized via splitting by space. ``tokenized_column: [[string]]``.\n",
    "3. Dictionary estimation.\n",
    "4. Each string in tokenized column is converted into token_id from dictionary. ``text: [[token_id]]``.\n",
    "5. Depending on the parameters CatBoost produce features basing on the resulting text column: Bag of words, Multinomial naive bayes or Bm25.\n",
    "6. Computed float features are passed into the usual CatBoost learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to pass these configs ([docs](https://catboost.ai/en/docs/references/training-parameters/text-processing#text_processing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_text_processing = {\n",
    "    \"tokenizers\" : [{\n",
    "        \"tokenizer_id\" : \"Space\",\n",
    "        \"separator_type\" : \"ByDelimiter\",\n",
    "        \"delimiter\" : \" \"\n",
    "    }],\n",
    "\n",
    "    \"dictionaries\" : [{\n",
    "        \"dictionary_id\" : \"BiGram\",\n",
    "        \"max_dictionary_size\" : \"50000\",\n",
    "        \"occurrence_lower_bound\" : \"3\",\n",
    "        \"gram_order\" : \"2\"\n",
    "    }, {\n",
    "        \"dictionary_id\" : \"Word\",\n",
    "        \"max_dictionary_size\" : \"50000\",\n",
    "        \"occurrence_lower_bound\" : \"3\",\n",
    "        \"gram_order\" : \"1\"\n",
    "    }],\n",
    "\n",
    "    \"feature_processing\" : {\n",
    "        \"default\" : [{\n",
    "            \"dictionaries_names\" : [\"BiGram\", \"Word\"],\n",
    "            \"feature_calcers\" : [\"BoW\"],\n",
    "            \"tokenizers_names\" : [\"Space\"]\n",
    "        }, {\n",
    "            \"dictionaries_names\" : [\"Word\"],\n",
    "            \"feature_calcers\" : [\"NaiveBayes\"],\n",
    "            \"tokenizers_names\" : [\"Space\"]\n",
    "        }],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text_processing = {\n",
    "    \"tokenizers\" : [{\n",
    "        \"tokenizer_id\" : \"Sense\",\n",
    "        \"separator_type\" : \"BySense\",\n",
    "    }],\n",
    "\n",
    "    \"dictionaries\" : [{\n",
    "        \"dictionary_id\" : \"BiGram\",\n",
    "        \"max_dictionary_size\" : \"50000\",\n",
    "        \"occurrence_lower_bound\" : \"3\",\n",
    "        \"gram_order\" : \"2\"\n",
    "    }, {\n",
    "        \"dictionary_id\" : \"Word\",\n",
    "        \"max_dictionary_size\" : \"50000\",\n",
    "        \"occurrence_lower_bound\" : \"3\",\n",
    "        \"gram_order\" : \"1\"\n",
    "    }, {\n",
    "        \"dictionary_id\" : \"TriGram\",\n",
    "        \"max_dictionary_size\" : \"50000\",\n",
    "        \"occurrence_lower_bound\" : \"3\",\n",
    "        \"gram_order\" : \"3\"\n",
    "    }],\n",
    "\n",
    "    \"feature_processing\" : {\n",
    "        \"default\" : [{\n",
    "            \"dictionaries_names\" : [\"TriGram\", \"BiGram\", \"Word\"],\n",
    "            \"feature_calcers\" : [\"BoW\"],\n",
    "            \"tokenizers_names\" : [\"Sense\"]\n",
    "        }, {\n",
    "            \"dictionaries_names\" : [\"TriGram\", \"BiGram\", \"Word\"],\n",
    "            \"feature_calcers\" : [\"NaiveBayes\"],\n",
    "            \"tokenizers_names\" : [\"Sense\"]\n",
    "        }, {\n",
    "            \"dictionaries_names\" : [\"TriGram\", \"BiGram\", \"Word\"],\n",
    "            \"feature_calcers\" : [\"BM25\"],\n",
    "            \"tokenizers_names\" : [\"Sense\"]\n",
    "        }],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e5e6d91ea9465d90863103f74fa93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = fit_model(train_pool, test_pool, text_processing=my_text_processing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for the record:\n",
    "\n",
    "With improved feature geneartion we are able to achieve:\n",
    "* AUC = 0.9727 (0.0133 gain over the baseline)\n",
    "* Accuracy = 0.9204 (0.0243 gain over the baseline)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
